{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Intro](#Intro)\n",
    "\t* [Autoencoder](#Autoencoder)\n",
    "* [Numbers Encoding (Keras)](#Numbers-Encoding-%28Keras%29)\n",
    "* [MNIST (Keras)](#MNIST-%28Keras%29)\n",
    "* [Variational Autoencoders](#Variational-Autoencoders)\n",
    "\t* [Encoder](#Encoder)\n",
    "\t* [Decoder](#Decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory notebook related to Autoencoders. Includes toy examples implementation and testing of related techniques or subjects.\n",
    "\n",
    "### Resources\n",
    "\n",
    "[Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of an autoencoder is to learn a compressed and distributed representation of a dataset. In the most general case it is then required for the autoencoder to be able to reconstruct the original input as accurately as possible. This technique implicitly operates feature extraction and learning, which generally would outperform handcrafted features results.\n",
    "\n",
    "For a single-layer feedforward net this can be achieved by using an hidden size smaller than the input one, and training on a function that consider how well the net is then able to reconstruct the input data. If hidden size is equal or higher than input size, the net should learn the identity matrix.\n",
    "\n",
    "Additional concepts:\n",
    "* sparsity and regularization\n",
    "* Denoising Autoencoders (DAE):  where the training is between a corrupted version of the input and the correct one as output\n",
    "* Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:01.998533",
     "start_time": "2017-10-20T08:34:31.525790Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pdb\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Activation, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.datasets import mnist\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "from utils.plot_utils import plot_sample_imgs\n",
    "from utils import image_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = \"/Users/amartinelli/Documents/datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Numbers Encoding (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An autoencoder that tries to learn a compressed (?binary) representation for one-hot encoded numbers.\n",
    "    \n",
    "1 = 00001  \n",
    "2 = 00010  \n",
    "3 = 00100  \n",
    "4 = 01000  \n",
    "5 = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:47:55.858799",
     "start_time": "2017-07-24T08:47:55.844799Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create one-hot encoded numbers\n",
    "input_dim = 10\n",
    "nums = np.eye(input_dim)[np.arange(input_dim)]\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:48:17.566041",
     "start_time": "2017-07-24T08:48:17.469035Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "hidden_size = input_dim//2\n",
    "\n",
    "# Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_size, input_dim=input_dim, activation=K.sigmoid))\n",
    "model.add(Dense(input_dim, activation=K.sigmoid))\n",
    "          \n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:48:25.564498",
     "start_time": "2017-07-24T08:48:18.477093Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(nums, nums, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:16.904435",
     "start_time": "2017-07-24T08:49:16.884434Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "layer_name = 'dense_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:20.294629",
     "start_time": "2017-07-24T08:49:20.153621Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hidden layer weights\n",
    "sns.heatmap(model.get_layer(layer_name).get_weights()[0])\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:29.666165",
     "start_time": "2017-07-24T08:49:29.634163Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get hidden layer output building \"intermediate model\"\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:30.445209",
     "start_time": "2017-07-24T08:49:30.433209Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:31.476268",
     "start_time": "2017-07-24T08:49:31.330260Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "sns.heatmap(model.predict(nums[np.array([1,2,3,5,6])]))\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# MNIST (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train autoencoder on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:34.591878",
     "start_time": "2017-07-24T08:50:34.586878Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:35.973957",
     "start_time": "2017-07-24T08:50:35.700942Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:36.471986",
     "start_time": "2017-07-24T08:50:36.448985Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "# get only subset of images\n",
    "num_images = 1000\n",
    "X_train = X_train[:num_images].reshape(num_images, num_pixels).astype('float32')\n",
    "X_test = X_test[:num_images].reshape(num_images, num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:37.136024",
     "start_time": "2017-07-24T08:50:37.125023Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:39.233144",
     "start_time": "2017-07-24T08:50:39.048133Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=num_pixels, activation=K.relu))\n",
    "model.add(Dense(256, activation=K.relu))\n",
    "model.add(Dense(512, activation=K.relu))\n",
    "model.add(Dense(num_pixels, activation=K.relu))\n",
    "          \n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:41.298262",
     "start_time": "2017-07-24T08:50:41.280261Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:48.890696",
     "start_time": "2017-07-24T08:50:46.052534Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, X_train, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:55.256060",
     "start_time": "2017-07-24T08:50:55.203057Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show original test example\n",
    "sns.plt.imshow(X_test[5].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T08:42:02.344610",
     "start_time": "2017-07-17T08:42:02.292607Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show predicted results\n",
    "pred = model.predict(X_test[5].reshape(1, num_pixels))\n",
    "plt.imshow(pred.reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T08:43:25.263352",
     "start_time": "2017-07-17T08:43:24.347300Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show several original test examples\n",
    "plot_sample_imgs(lambda size: np.random.choice(X_train, size), (28, 28), \n",
    "                 plot_side=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T08:43:34.789897",
     "start_time": "2017-07-17T08:43:33.607830Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show predicted results\n",
    "plot_sample_imgs(lambda size: np.random.choice(X_test, size), (28, 28), \n",
    "                 plot_side=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one constrain separates a normal autoencoder from a variational one: forcing \"it to generate latent vectors that roughly follow a unit Gaussian distribution\". The generation process is then about sampling a latent vector and feeding it to the decoder.\n",
    "\n",
    "[Source](http://kvfrans.com/variational-autoencoders-explained/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:26.672945",
     "start_time": "2017-10-20T08:35:26.666944Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils.generic_utils import Progbar\n",
    "\n",
    "from keras import objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:50.426303",
     "start_time": "2017-10-20T08:35:50.423303Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#img_shape = (28, 28, 1) # MNIST\n",
    "img_shape = (88, 104, 3) # CELEBA\n",
    "latent_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:53.025452",
     "start_time": "2017-10-20T08:35:53.014451Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility for the standard convolution block used in the encoder\n",
    "def encoder_conv_block(filters, block_input, kernel_size=(3, 3), strides=(1, 1)):\n",
    "    block = Convolution2D(filters, kernel_size, strides=strides, padding='same')(block_input)\n",
    "    block = LeakyReLU()(block)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:53.193462",
     "start_time": "2017-10-20T08:35:53.180461Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes an image and generates two vectors: means and standards deviations\n",
    "def encoder_model(input_shape, latent_dim, init_filters=64, num_conv_blocks=2):\n",
    "    input_image = Input(shape=input_shape)\n",
    "    \n",
    "    x = input_image\n",
    "    for i in range(num_conv_blocks):\n",
    "        x = encoder_conv_block(init_filters*(2**i), block_input=x)\n",
    "\n",
    "    features = Flatten()(x)\n",
    "    \n",
    "    mean_vector = Dense(latent_dim, activation='linear')(features)\n",
    "    std_vector = Dense(latent_dim, activation='linear')(features)\n",
    "    \n",
    "    return Model(inputs=[input_image], outputs=[mean_vector, std_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:36:02.420989",
     "start_time": "2017-10-20T08:36:02.233979Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate discriminator model\n",
    "encoder = encoder_model(input_shape=img_shape, latent_dim=latent_dim, init_filters=128)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:37:59.781702",
     "start_time": "2017-10-20T08:37:58.611635Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder.predict(np.random.randint(0, 256, (1, *img_shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:46:35.158180",
     "start_time": "2017-10-20T08:46:35.151179Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility for the standard deconvolution block used in the decoder\n",
    "def decoder_deconv_block(filters, block_input, kernel_size=(3, 3), strides=(1, 1)):\n",
    "    block = UpSampling2D()(block_input)\n",
    "    block = Convolution2D(filters, (3, 3), strides=strides, padding='same')(block)\n",
    "    block = LeakyReLU()(block)\n",
    "    block = BatchNormalization()(block)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_initial_size(final_size, num_deconv_blocks, factor=2):\n",
    "    if num_deconv_blocks==0:\n",
    "        return final_size\n",
    "    else:\n",
    "        return get_initial_size(final_size//factor, \n",
    "                                num_deconv_blocks-1, \n",
    "                                factor=factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:48:08.622526",
     "start_time": "2017-10-20T08:48:08.601525Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes as input both the prior sample (noise) and the image class\n",
    "def decoder_model(latent_dim, img_shape, init_filters=128, num_deconv_blocks=2):\n",
    "    latent_vector = Input([latent_dim])\n",
    "    init_shape = tuple([get_initial_size(d, num_deconv_blocks) \n",
    "                        for d in img_shape[:-1]]+[init_filters])\n",
    "    \n",
    "    # CNN part\n",
    "    x = Dense(1024)(latent_vector)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Dense(np.prod(init_shape))(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Reshape(init_shape)(x)\n",
    "\n",
    "    for i in range(num_deconv_blocks):\n",
    "        x = decoder_deconv_block(init_filters//(2**i+1), block_input=x)\n",
    "\n",
    "    x = Convolution2D(img_shape[-1], (2, 2), padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=latent_vector, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:48:09.877598",
     "start_time": "2017-10-20T08:48:09.545579Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate generate model\n",
    "decoder = decoder_model(latent_dim=latent_dim, \n",
    "                        img_shape=img_shape,\n",
    "                        init_filters=128,\n",
    "                       num_deconv_blocks=2)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tuple(decoder.output.shape.as_list()[1:])==img_shape,\\\n",
    "      \"Decoder output shape is different from input image shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:50:59.283287",
     "start_time": "2017-10-20T08:50:58.794259Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot random generated image\n",
    "plt.imshow(decoder.predict([np.random.randn(1, latent_dim)])[0]\n",
    "           .reshape(*img_shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V-Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model components\n",
    "encoder = encoder_model(input_shape=img_shape, latent_dim=latent_dim, init_filters=128)\n",
    "decoder = decoder_model(latent_dim=latent_dim, \n",
    "                        img_shape=img_shape,\n",
    "                        init_filters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample latent vector using our learned distribution parameters\n",
    "def sampling(z_mean, z_log_sigma, batch_size, latent_dim):\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=1.)\n",
    "    return z_mean + z_log_sigma * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "batch_size = 32\n",
    "\n",
    "input_img = Input(shape=(img_shape))\n",
    "mean_vector, std_vector = encoder(inputs=input_img)\n",
    "\n",
    "latent_vector = Lambda(lambda x : sampling(x[0], x[1], \n",
    "                                           batch_size, \n",
    "                                           latent_dim))([mean_vector, std_vector])\n",
    "\n",
    "output_img = decoder(latent_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the loss consider the sum of the generative loss\n",
    "# and the latent loss (KL divergence)\n",
    "def vae_loss(real_image, generated_image):\n",
    "    gen_loss = K.mean(objectives.mean_squared_error(real_image, generated_image))\n",
    "    kl_loss = 0.5 * K.mean(K.square(std_vector) + K.square(mean_vector) - K.log(K.square(std_vector)) -1, axis=-1)\n",
    "    return gen_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae = Model(inputs=input_img, outputs=output_img)\n",
    "vae.compile(loss=vae_loss, \n",
    "            optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## MNIST Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load mnist data using Keras\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape and normalize train data\n",
    "X_train = X_train[:1000]\n",
    "X_train = X_train[len(X_train)%batch_size:] # ??need divisible by batch size?\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_train = X_train.astype('float32')/255\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vae.fit(X_train, X_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "## CelebA Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load all imgs filepaths for the celeba database\n",
    "dir_path = os.path.join(data_folder, 'img_align_celeba')\n",
    "imgs_filepath = [os.path.join(dir_path, img_name) for img_name in os.listdir(dir_path)]\n",
    "print(len(imgs_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load subset of images and normalize\n",
    "X_train = image_processing.load_data(imgs_filepath[:300],\n",
    "                                 img_size=img_shape[:2])\n",
    "X_train = X_train[len(X_train)%batch_size:]\n",
    "X_train = X_train.astype('float32')/255\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vae.fit(X_train, X_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot VAE results\n",
    "plot_sample_imgs(lambda x: vae.predict(X_train[:32]), \n",
    "                 img_shape=img_shape,\n",
    "                plot_side=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot decoder results\n",
    "plot_sample_imgs(lambda x: decoder.predict([np.random.randn(16, latent_dim)]), \n",
    "                 img_shape=img_shape,\n",
    "                plot_side=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TOFIX random dummy method\n",
    "def manifold(n):\n",
    "    pred = encoder.predict(X_train[:1])[0]\n",
    "    grid_x = np.linspace(np.min(pred), np.max(pred), n)\n",
    "    grid_y = np.linspace(np.min(pred), np.max(pred), n)\n",
    "    \n",
    "    samples = []\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            #z_sample = np.array([[xi, yi, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,]])\n",
    "            z_sample = pred.copy()\n",
    "            z_sample[0][0] += yi\n",
    "            z_sample[0][1] += xi\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            samples.append(x_decoded[0])\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_sample_imgs(manifold,\n",
    "                 img_shape=img_shape,\n",
    "                plot_side=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:image-processing]",
   "language": "python",
   "name": "conda-env-image-processing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "704px",
    "left": "0px",
    "right": "1229px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
