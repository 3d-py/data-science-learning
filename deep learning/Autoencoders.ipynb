{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Intro](#Intro)\n",
    "\t* [Autoencoder](#Autoencoder)\n",
    "* [Numbers Encoding (Keras)](#Numbers-Encoding-%28Keras%29)\n",
    "* [MNIST (Keras)](#MNIST-%28Keras%29)\n",
    "* [Variational Autoencoders](#Variational-Autoencoders)\n",
    "\t* [Encoder](#Encoder)\n",
    "\t* [Decoder](#Decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory notebook related to Autoencoders. Includes toy examples implementation and testing of related techniques or subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of an autoencoder is to learn a compressed and distributed representation of a dataset. In the most general case it is then required for the autoencoder to be able to reconstruct the original input as accurately as possible. This technique implicitly operates feature extraction and learning, which generally would outperform handcrafted features results.\n",
    "\n",
    "For a single-layer feedforward net this can be achieved by using an hidden size smaller than the input one, and training on a function that consider how well the net is then able to reconstruct the input data. If hidden size is equal or higher than input size, the net should learn the identity matrix.\n",
    "\n",
    "Additional concepts:\n",
    "* sparsity and regularization\n",
    "* Denoising Autoencoders (DAE):  where the training is between a corrupted version of the input and the correct one as output\n",
    "* Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:01.998533",
     "start_time": "2017-10-20T08:34:31.525790Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pdb\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Activation, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "from utils.plot_utils import plot_sample_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numbers Encoding (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder that tries to learn a compressed (?binary) representation for one-hot encoded numbers.\n",
    "    \n",
    "1 = 00001  \n",
    "2 = 00010  \n",
    "3 = 00100  \n",
    "4 = 01000  \n",
    "5 = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:47:55.858799",
     "start_time": "2017-07-24T08:47:55.844799Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create one-hot encoded numbers\n",
    "input_dim = 10\n",
    "nums = np.eye(input_dim)[np.arange(input_dim)]\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:48:17.566041",
     "start_time": "2017-07-24T08:48:17.469035Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "hidden_size = input_dim//2\n",
    "\n",
    "# Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_size, input_dim=input_dim, activation=K.sigmoid))\n",
    "model.add(Dense(input_dim, activation=K.sigmoid))\n",
    "          \n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:48:25.564498",
     "start_time": "2017-07-24T08:48:18.477093Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(nums, nums, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:16.904435",
     "start_time": "2017-07-24T08:49:16.884434Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "layer_name = 'dense_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:20.294629",
     "start_time": "2017-07-24T08:49:20.153621Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hidden layer weights\n",
    "sns.heatmap(model.get_layer(layer_name).get_weights()[0])\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:29.666165",
     "start_time": "2017-07-24T08:49:29.634163Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get hidden layer output building \"intermediate model\"\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:30.445209",
     "start_time": "2017-07-24T08:49:30.433209Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:49:31.476268",
     "start_time": "2017-07-24T08:49:31.330260Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "sns.heatmap(model.predict(nums[np.array([1,2,3,5,6])]))\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MNIST (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train autoencoder on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:34.591878",
     "start_time": "2017-07-24T08:50:34.586878Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:35.973957",
     "start_time": "2017-07-24T08:50:35.700942Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:36.471986",
     "start_time": "2017-07-24T08:50:36.448985Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "# get only subset of images\n",
    "num_images = 1000\n",
    "X_train = X_train[:num_images].reshape(num_images, num_pixels).astype('float32')\n",
    "X_test = X_test[:num_images].reshape(num_images, num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:37.136024",
     "start_time": "2017-07-24T08:50:37.125023Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:39.233144",
     "start_time": "2017-07-24T08:50:39.048133Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=num_pixels, activation=K.relu))\n",
    "model.add(Dense(256, activation=K.relu))\n",
    "model.add(Dense(512, activation=K.relu))\n",
    "model.add(Dense(num_pixels, activation=K.relu))\n",
    "          \n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:41.298262",
     "start_time": "2017-07-24T08:50:41.280261Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:48.890696",
     "start_time": "2017-07-24T08:50:46.052534Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, X_train, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T08:50:55.256060",
     "start_time": "2017-07-24T08:50:55.203057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show original test example\n",
    "sns.plt.imshow(X_test[5].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T08:42:02.344610",
     "start_time": "2017-07-17T08:42:02.292607Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show predicted results\n",
    "pred = model.predict(X_test[5].reshape(1, num_pixels))\n",
    "plt.imshow(pred.reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T08:43:25.263352",
     "start_time": "2017-07-17T08:43:24.347300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show several original test examples\n",
    "plot_sample_imgs(lambda size: np.random.choice(X_train, size), (28, 28), \n",
    "                 plot_side=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T08:43:34.789897",
     "start_time": "2017-07-17T08:43:33.607830Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show predicted results\n",
    "plot_sample_imgs(lambda size: np.random.choice(X_test, size), (28, 28), \n",
    "                 plot_side=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one constrain separates a normal autoencoder from a variational one: forcing \"it to generate latent vectors that roughly follow a unit Gaussian distribution\". The generation process is then about sampling a latent vector and feeding it to the decoder.\n",
    "\n",
    "[Source](http://kvfrans.com/variational-autoencoders-explained/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:26.672945",
     "start_time": "2017-10-20T08:35:26.666944Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils.generic_utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:50.426303",
     "start_time": "2017-10-20T08:35:50.423303Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_shape = (28, 28, 1)\n",
    "latent_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:53.025452",
     "start_time": "2017-10-20T08:35:53.014451Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility for the standard convolution block used in the encoder\n",
    "def encoder_conv_block(filters, block_input, kernel_size=(3, 3), strides=(1, 1)):\n",
    "    block = Convolution2D(filters, kernel_size, strides=strides, padding='same')(block_input)\n",
    "    block = LeakyReLU()(block)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:35:53.193462",
     "start_time": "2017-10-20T08:35:53.180461Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes an image and generates two vectors: means and standards deviations\n",
    "def encoder_model(input_shape, latent_dim, init_filters=64, num_conv_blocks=2):\n",
    "    input_image = Input(shape=input_shape)\n",
    "    \n",
    "    x = input_image\n",
    "    for i in range(num_conv_blocks):\n",
    "        x = encoder_conv_block(init_filters*(2**i), block_input=x)\n",
    "\n",
    "    features = Flatten()(x)\n",
    "    \n",
    "    mean_vector = Dense(latent_dim, activation='linear')(features)\n",
    "    std_vector = Dense(latent_dim, activation='linear')(features)\n",
    "    \n",
    "    return Model(inputs=[input_image], outputs=[mean_vector, std_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:36:02.420989",
     "start_time": "2017-10-20T08:36:02.233979Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate discriminator model\n",
    "encoder = encoder_model(input_shape=img_shape, latent_dim=latent_dim, init_filters=128)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:37:59.781702",
     "start_time": "2017-10-20T08:37:58.611635Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder.predict(np.random.randint(0, 256, (1, 28,28, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:46:35.158180",
     "start_time": "2017-10-20T08:46:35.151179Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility for the standard deconvolution block used in the decoder\n",
    "def decoder_deconv_block(filters, block_input, kernel_size=(3, 3), strides=(1, 1)):\n",
    "    block = UpSampling2D()(block_input)\n",
    "    block = Convolution2D(filters, (3, 3), strides=strides, padding='same')(block)\n",
    "    block = LeakyReLU()(block)\n",
    "    block = BatchNormalization()(block)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:48:08.622526",
     "start_time": "2017-10-20T08:48:08.601525Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes as input both the prior sample (noise) and the image class\n",
    "def decoder_model(latent_dim, init_filters=128, init_side=7, num_deconv_blocks=2):\n",
    "    latent_vector = Input([latent_dim])\n",
    "    \n",
    "    # CNN part\n",
    "    x = Dense(1024)(latent_vector)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Dense(init_side*init_side*init_filters)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Reshape((init_side, init_side, init_filters))(x)\n",
    "\n",
    "    for i in range(num_deconv_blocks):\n",
    "        x = decoder_deconv_block(init_filters//(2**i+1), block_input=x)\n",
    "\n",
    "    x = Convolution2D(1, (2, 2), padding='same', activation='tanh')(x)\n",
    "    \n",
    "    return Model(inputs=latent_vector, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:48:09.877598",
     "start_time": "2017-10-20T08:48:09.545579Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate generate model\n",
    "decoder = decoder_model(latent_dim=latent_dim, init_filters=128)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T08:50:59.283287",
     "start_time": "2017-10-20T08:50:58.794259Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot random generated image\n",
    "plt.imshow(decoder.predict([np.random.randn(1, latent_dim)])[0]\n",
    "           .reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V-Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init model components\n",
    "encoder = encoder_model(input_shape=img_shape, latent_dim=latent_dim, init_filters=128)\n",
    "decoder = decoder_model(latent_dim=latent_dim, init_filters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "input_img = Input(shape=(img_shape))\n",
    "mean_vector, std_vector = encoder(inputs=input_img)\n",
    "latent_vector = \n",
    "output_img = decoder(latent_vector)\n",
    "\n",
    "vaut = Model(inputs=input_img, outputs=output_img)\n",
    "vaut.compile(loss=[d_loss, 'sparse_categorical_crossentropy'], \n",
    "            optimizer=RMSprop(lr=5e-5))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
